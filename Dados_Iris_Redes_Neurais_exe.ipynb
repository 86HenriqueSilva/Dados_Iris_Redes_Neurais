{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPR96KnZ3FYyfx95TimFCGp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/86HenriqueSilva/Dados_Iris_Redes_Neurais_Grafico/blob/main/Dados_Iris_Redes_Neurais_exe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3mksrkVaxTZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.exceptions import ConvergenceWarning, FitFailedWarning\n",
        "import warnings\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "# Suprimir warnings de convergência para MLPClassifier\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
        "\n",
        "# Carregar o conjunto de dados Iris\n",
        "iris = load_iris()\n",
        "\n",
        "# Definir os percentuais de dados de treinamento\n",
        "percentuais_treinamento = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "\n",
        "# Definir o número de repetições\n",
        "num_repeticoes = 20\n",
        "\n",
        "# Inicializar dicionários para armazenar os resultados\n",
        "resultados_knn_1 = {}\n",
        "resultados_knn_3 = {}\n",
        "resultados_knn_5 = {}\n",
        "resultados_dmc = {}\n",
        "resultados_mlp = {}\n",
        "\n",
        "# Inicializar o tempo de início\n",
        "start_time = time.time()\n",
        "\n",
        "# Loop através dos diferentes percentuais de treinamento\n",
        "for percentual_treinamento in percentuais_treinamento:\n",
        "    # Inicializar listas para armazenar resultados de cada repetição\n",
        "    acuracias_knn_1 = []\n",
        "    acuracias_knn_3 = []\n",
        "    acuracias_knn_5 = []\n",
        "    acuracias_dmc = []\n",
        "    acuracias_mlp = []\n",
        "\n",
        "    for _ in range(num_repeticoes):\n",
        "        # Dividir os dados em conjunto de treinamento e teste\n",
        "        X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=1-percentual_treinamento)\n",
        "\n",
        "        # KNN com k=1\n",
        "        knn_1 = KNeighborsClassifier(n_neighbors=1)\n",
        "        acuracia_knn_1 = np.mean(cross_val_score(knn_1, X_train, y_train, cv=5))\n",
        "        acuracias_knn_1.append(acuracia_knn_1)\n",
        "\n",
        "        # KNN com k=3\n",
        "        knn_3 = KNeighborsClassifier(n_neighbors=3)\n",
        "        acuracia_knn_3 = np.mean(cross_val_score(knn_3, X_train, y_train, cv=5))\n",
        "        acuracias_knn_3.append(acuracia_knn_3)\n",
        "\n",
        "        # KNN com k=5\n",
        "        knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
        "        acuracia_knn_5 = np.mean(cross_val_score(knn_5, X_train, y_train, cv=5))\n",
        "        acuracias_knn_5.append(acuracia_knn_5)\n",
        "\n",
        "        # DMC\n",
        "        try:\n",
        "            dmc = QuadraticDiscriminantAnalysis()\n",
        "            acuracia_dmc = np.mean(cross_val_score(dmc, X_train, y_train, cv=5))\n",
        "            acuracias_dmc.append(acuracia_dmc)\n",
        "        except Exception as e:\n",
        "            acuracias_dmc.append(np.nan)\n",
        "\n",
        "        # MLP\n",
        "        mlp = MLPClassifier()\n",
        "        parameters = {'hidden_layer_sizes': [(10,), (50,), (100,)],\n",
        "                      'activation': ['tanh', 'relu'],\n",
        "                      'solver': ['sgd', 'adam'],\n",
        "                      'alpha': [0.0001, 0.05]}\n",
        "        mlp_grid = GridSearchCV(mlp, parameters, cv=5)\n",
        "        mlp_grid.fit(X_train, y_train)\n",
        "        acuracia_mlp = mlp_grid.best_score_\n",
        "        acuracias_mlp.append(acuracia_mlp)\n",
        "\n",
        "    # Armazenar as estatísticas de desempenho para cada percentual de treinamento\n",
        "    resultados_knn_1[percentual_treinamento] = {\n",
        "        'min': np.min(acuracias_knn_1),\n",
        "        'max': np.max(acuracias_knn_1),\n",
        "        'media': np.mean(acuracias_knn_1),\n",
        "        'desvio_padrao': np.std(acuracias_knn_1)\n",
        "    }\n",
        "\n",
        "    resultados_knn_3[percentual_treinamento] = {\n",
        "        'min': np.min(acuracias_knn_3),\n",
        "        'max': np.max(acuracias_knn_3),\n",
        "        'media': np.mean(acuracias_knn_3),\n",
        "        'desvio_padrao': np.std(acuracias_knn_3)\n",
        "    }\n",
        "\n",
        "    resultados_knn_5[percentual_treinamento] = {\n",
        "        'min': np.min(acuracias_knn_5),\n",
        "        'max': np.max(acuracias_knn_5),\n",
        "        'media': np.mean(acuracias_knn_5),\n",
        "        'desvio_padrao': np.std(acuracias_knn_5)\n",
        "    }\n",
        "\n",
        "    resultados_dmc[percentual_treinamento] = {\n",
        "        'min': np.nanmin(acuracias_dmc),\n",
        "        'max': np.nanmax(acuracias_dmc),\n",
        "        'media': np.nanmean(acuracias_dmc),\n",
        "        'desvio_padrao': np.nanstd(acuracias_dmc)\n",
        "    }\n",
        "\n",
        "    resultados_mlp[percentual_treinamento] = {\n",
        "        'min': np.min(acuracias_mlp),\n",
        "        'max': np.max(acuracias_mlp),\n",
        "        'media': np.mean(acuracias_mlp),\n",
        "        'desvio_padrao': np.std(acuracias_mlp)\n",
        "    }\n",
        "\n",
        "# Imprimir resultados\n",
        "print(\"Resultados para KNN (k=1):\")\n",
        "for percentual, estatisticas in resultados_knn_1.items():\n",
        "    print(f\"Percentual de treinamento: {percentual:.0%}\")\n",
        "    print(f\"Mínimo: {estatisticas['min']:.2f}\")\n",
        "    print(f\"Máximo: {estatisticas['max']:.2f}\")\n",
        "    print(f\"Média: {estatisticas['media']:.2f}\")\n",
        "    print(f\"Desvio padrão: {estatisticas['desvio_padrao']:.2f}\")\n",
        "    print()\n",
        "\n",
        "# Repetir para os outros algoritmos\n",
        "print(\"Resultados para KNN (k=3):\")\n",
        "for percentual, estatisticas in resultados_knn_3.items():\n",
        "    print(f\"Percentual de treinamento: {percentual:.0%}\")\n",
        "    print(f\"Mínimo: {estatisticas['min']:.2f}\")\n",
        "    print(f\"Máximo: {estatisticas['max']:.2f}\")\n",
        "    print(f\"Média: {estatisticas['media']:.2f}\")\n",
        "    print(f\"Desvio padrão: {estatisticas['desvio_padrao']:.2f}\")\n",
        "    print()\n",
        "\n",
        "print(\"Resultados para KNN (k=5):\")\n",
        "for percentual, estatisticas in resultados_knn_5.items():\n",
        "    print(f\"Percentual de treinamento: {percentual:.0%}\")\n",
        "    print(f\"Mínimo: {estatisticas['min']:.2f}\")\n",
        "    print(f\"Máximo: {estatisticas['max']:.2f}\")\n",
        "    print(f\"Média: {estatisticas['media']:.2f}\")\n",
        "    print(f\"Desvio padrão: {estatisticas['desvio_padrao']:.2f}\")\n",
        "    print()\n",
        "\n",
        "print(\"Resultados para DMC:\")\n",
        "for percentual, estatisticas in resultados_dmc.items():\n",
        "    print(f\"Percentual de treinamento: {percentual:.0%}\")\n",
        "    print(f\"Mínimo: {estatisticas['min']:.2f}\")\n",
        "    print(f\"Máximo: {estatisticas['max']:.2f}\")\n",
        "    print(f\"Média: {estatisticas['media']:.2f}\")\n",
        "    print(f\"Desvio padrão: {estatisticas['desvio_padrao']:.2f}\")\n",
        "    print()\n",
        "\n",
        "print(\"Resultados para MLP:\")\n",
        "for percentual, estatisticas in resultados_mlp.items():\n",
        "    print(f\"Percentual de treinamento: {percentual:.0%}\")\n",
        "    print(f\"Mínimo: {estatisticas['min']:.2f}\")\n",
        "    print(f\"Máximo: {estatisticas['max']:.2f}\")\n",
        "    print(f\"Média: {estatisticas['media']:.2f}\")\n",
        "    print(f\"Desvio padrão: {estatisticas['desvio_padrao']:.2f}\")\n",
        "    print()\n",
        "\n",
        "# Calcular e imprimir tempo de execução\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Tempo de execução: {datetime.timedelta(seconds=round(execution_time))}\")\n",
        "\n",
        "# Obter e imprimir a data atual\n",
        "current_date = datetime.datetime.now()\n",
        "print(f\"Data atual: {current_date.strftime('%d/%m/%Y')}\")\n"
      ]
    }
  ]
}